{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cifar 100. Took a code from Kaggle and added WandB monitoring. Checked prediction."
      ],
      "metadata": {
        "id": "W_wrIcWKWm_s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X19FusabO6qn"
      },
      "outputs": [],
      "source": [
        "# Importing the required libraries and dataset\n",
        "import os\n",
        "import itertools\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Hide all TensorFlow debugging logs\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import densenet\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "sSBaxiMoSsKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU7iB59LSsyX",
        "outputId": "f75c538a-7b5d-46fe-c818-d9e7d1d47dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project='MLOPS-mini-cap-cifar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ITaS05L7TEuo",
        "outputId": "cff8e88e-8eed-4f16-fe27-dc0400f0c42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnrepesh\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/nrepesh/MLOPS-mini-cap-cifar/runs/3tzcuah2\" target=\"_blank\">fragrant-rain-1</a></strong> to <a href=\"https://wandb.ai/nrepesh/MLOPS-mini-cap-cifar\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset and pre-process data\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "oDRgNs2LPUqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bc20e6-b5f7-430f-e31c-0c07b83d0178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 3s 0us/step\n",
            "169017344/169001437 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into test and validation data\n",
        "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.7)"
      ],
      "metadata": {
        "id": "CmPrmGU6PXeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class labels\n",
        "labels =  ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', \n",
        "           'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', \n",
        "           'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', \n",
        "           'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', \n",
        "           'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', \n",
        "           'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n",
        "           'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', \n",
        "           'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', \n",
        "           'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']"
      ],
      "metadata": {
        "id": "eXV9HQAqPY5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one hot encoding matrix\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "y_valid = to_categorical(y_valid, 100)"
      ],
      "metadata": {
        "id": "17ujBDEfPp0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for model building\n",
        "def build_model(input_shape, n_classes):\n",
        "    \"\"\"\n",
        "    Build model from DenseNet. Retrain last 5 layers and adds 2 Dense layers.\n",
        "    :param input_shape: shape of single image\n",
        "    :param n_classes: number of classes for prediction\n",
        "    :return model: compiled model\n",
        "    \"\"\"\n",
        "    base_model = densenet.DenseNet121(input_shape=input_shape,\n",
        "                                      weights=\"imagenet\",\n",
        "                                      include_top=False,\n",
        "                                      pooling='avg')\n",
        "\n",
        "    for layer in base_model.layers[:-5]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    for layer in base_model.layers[-5:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "\n",
        "    x = Dense(128)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    predictions = Dense(n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RnPs1oFoPuT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model and get summary\n",
        "model = build_model(input_shape=(32, 32, 3), n_classes=len(labels))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgG7wuHcPwDv",
        "outputId": "71e031bc-3033-4746-ecac-3558718df5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "29097984/29084464 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 38, 38, 3)   0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 16, 16, 64)   9408        ['zero_padding2d[0][0]']         \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1/conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 16, 16, 64)   0           ['conv1/bn[0][0]']               \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 18, 18, 64)  0           ['conv1/relu[0][0]']             \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 8, 8, 64)     0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 64)    256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 128)    8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 8, 8, 96)    0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 8, 8, 96)    384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 8, 8, 96)    0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 128)    12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 8, 8, 128)   0           ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 128)    16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 8, 8, 160)   0           ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 8, 8, 160)   640         ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 8, 8, 160)   0           ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 8, 8, 128)    20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 8, 8, 192)   0           ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 8, 8, 192)   768         ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 8, 8, 192)   0           ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 8, 8, 128)    24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 8, 8, 224)   0           ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 8, 8, 224)   896         ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 8, 8, 224)   0           ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 8, 8, 128)    28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 8, 8, 256)   0           ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 8, 8, 256)    1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 8, 8, 256)    0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 8, 8, 128)    32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 4, 4, 128)    0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 128)   512         ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 4, 4, 160)   0           ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 4, 4, 160)   640         ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 4, 4, 160)   0           ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 4, 4, 192)   0           ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 4, 4, 192)   768         ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 4, 4, 192)   0           ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 4, 4, 224)   0           ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 4, 4, 224)   896         ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 4, 4, 224)   0           ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 4, 4, 256)   0           ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 4, 4, 256)   0           ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 4, 4, 128)    32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 4, 4, 288)   0           ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 4, 4, 288)   1152        ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 4, 4, 288)   0           ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 4, 4, 128)    36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 4, 4, 320)   0           ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 4, 4, 320)   1280        ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 4, 4, 320)   0           ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 4, 4, 128)    40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 4, 4, 352)   0           ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 4, 4, 352)   1408        ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 4, 4, 352)   0           ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 4, 4, 128)    45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 4, 4, 384)   0           ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 4, 4, 384)   1536        ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 4, 4, 384)   0           ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 4, 4, 128)    49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 4, 4, 416)   0           ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 4, 4, 416)   1664        ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 4, 4, 416)   0           ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 4, 4, 128)    53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 4, 4, 128)   0           ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 4, 4, 448)   0           ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 4, 4, 448)   1792        ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 4, 4, 448)   0           ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 4, 4, 128)    57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 4, 4, 128)   0           ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 4, 4, 480)   0           ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 4, 4, 480)   1920        ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 4, 4, 480)   0           ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 4, 4, 128)    61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 4, 4, 128)   0           ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 4, 4, 512)   0           ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 4, 4, 512)    2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 4, 4, 512)    0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 4, 4, 256)    131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 2, 2, 256)    0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 256)   1024        ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 128)    32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 2, 2, 288)   0           ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 2, 2, 288)   1152        ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 2, 2, 288)   0           ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 128)    36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 2, 2, 320)   0           ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 2, 2, 320)   1280        ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 2, 2, 320)   0           ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 128)    40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 2, 2, 352)   0           ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 2, 2, 352)   1408        ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 2, 2, 352)   0           ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 128)    45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 2, 2, 384)   0           ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 2, 2, 384)   1536        ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 2, 2, 384)   0           ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 128)    49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 2, 2, 416)   0           ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 2, 2, 416)   1664        ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 2, 2, 416)   0           ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 128)    53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 2, 2, 448)   0           ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 2, 2, 448)   1792        ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 2, 2, 448)   0           ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 2, 2, 128)    57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 2, 2, 480)   0           ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 2, 2, 480)   1920        ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 2, 2, 480)   0           ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 2, 2, 128)    61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 2, 2, 512)   0           ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 2, 2, 512)   0           ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 2, 2, 128)    65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 2, 2, 544)   0           ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 2, 2, 544)   2176        ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 2, 2, 544)   0           ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 2, 2, 128)    69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 2, 2, 576)   0           ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 2, 2, 576)   2304        ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 2, 2, 576)   0           ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 2, 2, 128)    73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 2, 2, 608)   0           ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 2, 2, 608)   2432        ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 2, 2, 608)   0           ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 2, 2, 128)    77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 2, 2, 640)   0           ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 2, 2, 640)   2560        ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 2, 2, 640)   0           ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 2, 2, 128)    81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 2, 2, 672)   0           ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 2, 2, 672)   2688        ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 2, 2, 672)   0           ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 2, 2, 128)    86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 2, 2, 704)   0           ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 2, 2, 704)   2816        ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 2, 2, 704)   0           ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 2, 2, 128)    90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 2, 2, 736)   0           ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 2, 2, 736)   2944        ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 2, 2, 736)   0           ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 2, 2, 128)    94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 2, 2, 768)   0           ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 2, 2, 768)   3072        ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 2, 2, 768)   0           ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 2, 2, 128)    98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 2, 2, 800)   0           ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 2, 2, 800)   3200        ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 2, 2, 800)   0           ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 2, 2, 128)    102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 2, 2, 832)   0           ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 2, 2, 832)   3328        ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 2, 2, 832)   0           ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 2, 2, 128)    106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 2, 2, 864)   0           ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 2, 2, 864)   3456        ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 2, 2, 864)   0           ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 2, 2, 128)    110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 2, 2, 896)   0           ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 2, 2, 896)   3584        ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 2, 2, 896)   0           ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 2, 2, 128)    114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 2, 2, 928)   0           ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 2, 2, 928)   3712        ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 2, 2, 928)   0           ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 2, 2, 128)    118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 2, 2, 960)   0           ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 2, 2, 960)   3840        ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 2, 2, 960)   0           ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 2, 2, 128)    122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 2, 2, 992)   0           ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 2, 2, 992)   3968        ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 2, 2, 992)   0           ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 2, 2, 128)    126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 2, 2, 1024)  0           ['conv4_block23_concat[0][0]',   \n",
            " ate)                                                             'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 2, 2, 1024)   4096        ['conv4_block24_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 2, 2, 1024)   0           ['pool4_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 2, 2, 512)    524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 1, 1, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 1, 1, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 1, 1, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 1, 1, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 1, 1, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 1, 1, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 1, 1, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 1, 1, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 1, 1, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 1, 1, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 1, 1, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 1, 1, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 1, 1, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 1, 1, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 1, 1, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 1, 1, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 1, 1, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 1, 1, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 1, 1, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 1, 1, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 1, 1, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 1, 1, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 1, 1, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 1, 1, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 1, 1, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 1, 1, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 1, 1, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 1, 1, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 1, 1, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 1, 1, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 1, 1, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 1, 1, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 1, 1, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 1, 1, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 1, 1, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 1, 1, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 1, 1, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 1, 1, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 1, 1, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 1, 1, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 1, 1, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 1, 1, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 1, 1, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 1, 1, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 1, 1, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 1, 1, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 1, 1, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 1, 1, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 1, 1, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 1, 1, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 1, 1, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 1, 1, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 1, 1, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 1, 1, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 1, 1, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 1, 1, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 1, 1, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 1, 1, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 1, 1, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 1, 1, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 1, 1, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 1, 1, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 1024)        0           ['relu[0][0]']                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          131200      ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 100)          12900       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,181,604\n",
            "Trainable params: 183,012\n",
            "Non-trainable params: 6,998,592\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate augmented images\n",
        "datagen = ImageDataGenerator(\n",
        "    height_shift_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=40,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest',\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "NZR__hfeP1Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set checkpointer and train model\n",
        "model_checkpointer = ModelCheckpoint('cifar100_best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=128, shuffle=True), \n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=60, \n",
        "    verbose=1,  \n",
        "    callbacks=[EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=15), \n",
        "               model_checkpointer,WandbCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUjNae08P5XV",
        "outputId": "c8fe6b63-0679-4812-cbc6-6cf8e32f756c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6570 - accuracy: 0.1622\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.26100, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 79s 158ms/step - loss: 3.6570 - accuracy: 0.1622 - val_loss: 2.9944 - val_accuracy: 0.2610\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1018 - accuracy: 0.2447\n",
            "Epoch 00002: val_accuracy improved from 0.26100 to 0.29786, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 3.1018 - accuracy: 0.2447 - val_loss: 2.7980 - val_accuracy: 0.2979\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9662 - accuracy: 0.2658\n",
            "Epoch 00003: val_accuracy improved from 0.29786 to 0.32871, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 2.9662 - accuracy: 0.2658 - val_loss: 2.6501 - val_accuracy: 0.3287\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8809 - accuracy: 0.2836\n",
            "Epoch 00004: val_accuracy improved from 0.32871 to 0.32900, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 60s 153ms/step - loss: 2.8809 - accuracy: 0.2836 - val_loss: 2.6238 - val_accuracy: 0.3290\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8129 - accuracy: 0.2954\n",
            "Epoch 00005: val_accuracy improved from 0.32900 to 0.34214, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 2.8129 - accuracy: 0.2954 - val_loss: 2.5760 - val_accuracy: 0.3421\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7795 - accuracy: 0.3008\n",
            "Epoch 00006: val_accuracy did not improve from 0.34214\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 2.7795 - accuracy: 0.3008 - val_loss: 2.5913 - val_accuracy: 0.3350\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7379 - accuracy: 0.3097\n",
            "Epoch 00007: val_accuracy did not improve from 0.34214\n",
            "391/391 [==============================] - 56s 143ms/step - loss: 2.7379 - accuracy: 0.3097 - val_loss: 2.5622 - val_accuracy: 0.3416\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7170 - accuracy: 0.3104\n",
            "Epoch 00008: val_accuracy improved from 0.34214 to 0.35886, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 60s 154ms/step - loss: 2.7170 - accuracy: 0.3104 - val_loss: 2.4826 - val_accuracy: 0.3589\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6872 - accuracy: 0.3193\n",
            "Epoch 00009: val_accuracy did not improve from 0.35886\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 2.6872 - accuracy: 0.3193 - val_loss: 2.4916 - val_accuracy: 0.3564\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6696 - accuracy: 0.3207\n",
            "Epoch 00010: val_accuracy improved from 0.35886 to 0.36086, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 56s 142ms/step - loss: 2.6696 - accuracy: 0.3207 - val_loss: 2.4913 - val_accuracy: 0.3609\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6623 - accuracy: 0.3244\n",
            "Epoch 00011: val_accuracy improved from 0.36086 to 0.36186, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 2.6623 - accuracy: 0.3244 - val_loss: 2.4804 - val_accuracy: 0.3619\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6336 - accuracy: 0.3298\n",
            "Epoch 00012: val_accuracy did not improve from 0.36186\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 2.6336 - accuracy: 0.3298 - val_loss: 2.4613 - val_accuracy: 0.3559\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6271 - accuracy: 0.3308\n",
            "Epoch 00013: val_accuracy improved from 0.36186 to 0.36657, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 58s 149ms/step - loss: 2.6271 - accuracy: 0.3308 - val_loss: 2.4326 - val_accuracy: 0.3666\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6067 - accuracy: 0.3358\n",
            "Epoch 00014: val_accuracy improved from 0.36657 to 0.37486, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 59s 150ms/step - loss: 2.6067 - accuracy: 0.3358 - val_loss: 2.4164 - val_accuracy: 0.3749\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5986 - accuracy: 0.3366\n",
            "Epoch 00015: val_accuracy did not improve from 0.37486\n",
            "391/391 [==============================] - 59s 150ms/step - loss: 2.5986 - accuracy: 0.3366 - val_loss: 2.4155 - val_accuracy: 0.3713\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5862 - accuracy: 0.3388\n",
            "Epoch 00016: val_accuracy did not improve from 0.37486\n",
            "391/391 [==============================] - 59s 151ms/step - loss: 2.5862 - accuracy: 0.3388 - val_loss: 2.4074 - val_accuracy: 0.3736\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5791 - accuracy: 0.3447\n",
            "Epoch 00017: val_accuracy improved from 0.37486 to 0.37500, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 59s 150ms/step - loss: 2.5791 - accuracy: 0.3447 - val_loss: 2.4248 - val_accuracy: 0.3750\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5711 - accuracy: 0.3441\n",
            "Epoch 00018: val_accuracy improved from 0.37500 to 0.37629, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 59s 150ms/step - loss: 2.5711 - accuracy: 0.3441 - val_loss: 2.4107 - val_accuracy: 0.3763\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5647 - accuracy: 0.3437\n",
            "Epoch 00019: val_accuracy did not improve from 0.37629\n",
            "391/391 [==============================] - 58s 149ms/step - loss: 2.5647 - accuracy: 0.3437 - val_loss: 2.4028 - val_accuracy: 0.3741\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5547 - accuracy: 0.3467\n",
            "Epoch 00020: val_accuracy did not improve from 0.37629\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 2.5547 - accuracy: 0.3467 - val_loss: 2.4169 - val_accuracy: 0.3763\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5337 - accuracy: 0.3493\n",
            "Epoch 00021: val_accuracy improved from 0.37629 to 0.37943, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 56s 144ms/step - loss: 2.5337 - accuracy: 0.3493 - val_loss: 2.4023 - val_accuracy: 0.3794\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5412 - accuracy: 0.3499\n",
            "Epoch 00022: val_accuracy did not improve from 0.37943\n",
            "391/391 [==============================] - 54s 139ms/step - loss: 2.5412 - accuracy: 0.3499 - val_loss: 2.4220 - val_accuracy: 0.3684\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5329 - accuracy: 0.3494\n",
            "Epoch 00023: val_accuracy did not improve from 0.37943\n",
            "391/391 [==============================] - 58s 149ms/step - loss: 2.5329 - accuracy: 0.3494 - val_loss: 2.3894 - val_accuracy: 0.3764\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5202 - accuracy: 0.3514\n",
            "Epoch 00024: val_accuracy did not improve from 0.37943\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.5202 - accuracy: 0.3514 - val_loss: 2.3824 - val_accuracy: 0.3783\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5121 - accuracy: 0.3530\n",
            "Epoch 00025: val_accuracy improved from 0.37943 to 0.38986, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 2.5121 - accuracy: 0.3530 - val_loss: 2.3704 - val_accuracy: 0.3899\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5140 - accuracy: 0.3540\n",
            "Epoch 00026: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.5140 - accuracy: 0.3540 - val_loss: 2.3853 - val_accuracy: 0.3806\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5141 - accuracy: 0.3558\n",
            "Epoch 00027: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 56s 143ms/step - loss: 2.5141 - accuracy: 0.3558 - val_loss: 2.3608 - val_accuracy: 0.3851\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5070 - accuracy: 0.3539\n",
            "Epoch 00028: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.5070 - accuracy: 0.3539 - val_loss: 2.4002 - val_accuracy: 0.3826\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4993 - accuracy: 0.3571\n",
            "Epoch 00029: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 55s 141ms/step - loss: 2.4993 - accuracy: 0.3571 - val_loss: 2.3732 - val_accuracy: 0.3820\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4989 - accuracy: 0.3554\n",
            "Epoch 00030: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.4989 - accuracy: 0.3554 - val_loss: 2.3654 - val_accuracy: 0.3844\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4899 - accuracy: 0.3577\n",
            "Epoch 00031: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.4899 - accuracy: 0.3577 - val_loss: 2.3608 - val_accuracy: 0.3834\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4820 - accuracy: 0.3600\n",
            "Epoch 00032: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.4820 - accuracy: 0.3600 - val_loss: 2.3725 - val_accuracy: 0.3831\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4886 - accuracy: 0.3586\n",
            "Epoch 00033: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 58s 149ms/step - loss: 2.4886 - accuracy: 0.3586 - val_loss: 2.3685 - val_accuracy: 0.3843\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4762 - accuracy: 0.3615\n",
            "Epoch 00034: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 59s 151ms/step - loss: 2.4762 - accuracy: 0.3615 - val_loss: 2.3459 - val_accuracy: 0.3861\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4694 - accuracy: 0.3666\n",
            "Epoch 00035: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.4694 - accuracy: 0.3666 - val_loss: 2.3686 - val_accuracy: 0.3871\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4670 - accuracy: 0.3633\n",
            "Epoch 00036: val_accuracy did not improve from 0.38986\n",
            "391/391 [==============================] - 55s 142ms/step - loss: 2.4670 - accuracy: 0.3633 - val_loss: 2.3373 - val_accuracy: 0.3886\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4636 - accuracy: 0.3630\n",
            "Epoch 00037: val_accuracy improved from 0.38986 to 0.39471, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 60s 152ms/step - loss: 2.4636 - accuracy: 0.3630 - val_loss: 2.3227 - val_accuracy: 0.3947\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4610 - accuracy: 0.3633\n",
            "Epoch 00038: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 54s 139ms/step - loss: 2.4610 - accuracy: 0.3633 - val_loss: 2.3636 - val_accuracy: 0.3841\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4534 - accuracy: 0.3640\n",
            "Epoch 00039: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.4534 - accuracy: 0.3640 - val_loss: 2.3564 - val_accuracy: 0.3854\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4597 - accuracy: 0.3649\n",
            "Epoch 00040: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 54s 139ms/step - loss: 2.4597 - accuracy: 0.3649 - val_loss: 2.3485 - val_accuracy: 0.3870\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4516 - accuracy: 0.3677\n",
            "Epoch 00041: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 53s 136ms/step - loss: 2.4516 - accuracy: 0.3677 - val_loss: 2.3260 - val_accuracy: 0.3857\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4420 - accuracy: 0.3695\n",
            "Epoch 00042: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 2.4420 - accuracy: 0.3695 - val_loss: 2.3593 - val_accuracy: 0.3883\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4366 - accuracy: 0.3673\n",
            "Epoch 00043: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 2.4366 - accuracy: 0.3673 - val_loss: 2.3740 - val_accuracy: 0.3870\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4398 - accuracy: 0.3687\n",
            "Epoch 00044: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 54s 139ms/step - loss: 2.4398 - accuracy: 0.3687 - val_loss: 2.3730 - val_accuracy: 0.3789\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4342 - accuracy: 0.3685\n",
            "Epoch 00045: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 54s 139ms/step - loss: 2.4342 - accuracy: 0.3685 - val_loss: 2.3429 - val_accuracy: 0.3861\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4381 - accuracy: 0.3697\n",
            "Epoch 00046: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.4381 - accuracy: 0.3697 - val_loss: 2.3570 - val_accuracy: 0.3859\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4291 - accuracy: 0.3719\n",
            "Epoch 00047: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 58s 149ms/step - loss: 2.4291 - accuracy: 0.3719 - val_loss: 2.3436 - val_accuracy: 0.3881\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4192 - accuracy: 0.3728\n",
            "Epoch 00048: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 55s 141ms/step - loss: 2.4192 - accuracy: 0.3728 - val_loss: 2.3271 - val_accuracy: 0.3884\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4235 - accuracy: 0.3745\n",
            "Epoch 00049: val_accuracy did not improve from 0.39471\n",
            "391/391 [==============================] - 58s 149ms/step - loss: 2.4235 - accuracy: 0.3745 - val_loss: 2.3416 - val_accuracy: 0.3936\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4230 - accuracy: 0.3725\n",
            "Epoch 00050: val_accuracy improved from 0.39471 to 0.39729, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 60s 154ms/step - loss: 2.4230 - accuracy: 0.3725 - val_loss: 2.3155 - val_accuracy: 0.3973\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4216 - accuracy: 0.3741\n",
            "Epoch 00051: val_accuracy improved from 0.39729 to 0.39757, saving model to cifar100_best_model.h5\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 2.4216 - accuracy: 0.3741 - val_loss: 2.3142 - val_accuracy: 0.3976\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4207 - accuracy: 0.3734\n",
            "Epoch 00052: val_accuracy did not improve from 0.39757\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 2.4207 - accuracy: 0.3734 - val_loss: 2.3362 - val_accuracy: 0.3926\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4141 - accuracy: 0.3754\n",
            "Epoch 00053: val_accuracy did not improve from 0.39757\n",
            "391/391 [==============================] - 60s 153ms/step - loss: 2.4141 - accuracy: 0.3754 - val_loss: 2.3351 - val_accuracy: 0.3970\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4126 - accuracy: 0.3738\n",
            "Epoch 00054: val_accuracy did not improve from 0.39757\n",
            "391/391 [==============================] - 60s 153ms/step - loss: 2.4126 - accuracy: 0.3738 - val_loss: 2.3177 - val_accuracy: 0.3904\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4116 - accuracy: 0.3747\n",
            "Epoch 00055: val_accuracy did not improve from 0.39757\n",
            "391/391 [==============================] - 60s 152ms/step - loss: 2.4116 - accuracy: 0.3747 - val_loss: 2.3371 - val_accuracy: 0.3900\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4054 - accuracy: 0.3746\n",
            "Epoch 00056: val_accuracy did not improve from 0.39757\n",
            "391/391 [==============================] - 60s 153ms/step - loss: 2.4054 - accuracy: 0.3746 - val_loss: 2.3464 - val_accuracy: 0.3923\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4043 - accuracy: 0.3749\n",
            "Epoch 00057: val_accuracy did not improve from 0.39757\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 2.4043 - accuracy: 0.3749 - val_loss: 2.3642 - val_accuracy: 0.3827\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4026 - accuracy: 0.3792\n",
            "Epoch 00058: val_accuracy did not improve from 0.39757\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 2.4026 - accuracy: 0.3792 - val_loss: 2.3401 - val_accuracy: 0.3901\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4032 - accuracy: 0.3769\n",
            "Epoch 00059: val_accuracy did not improve from 0.39757\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 2.4032 - accuracy: 0.3769 - val_loss: 2.3143 - val_accuracy: 0.3970\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3989 - accuracy: 0.3753\n",
            "Epoch 00060: val_accuracy did not improve from 0.39757\n",
            "391/391 [==============================] - 55s 140ms/step - loss: 2.3989 - accuracy: 0.3753 - val_loss: 2.3200 - val_accuracy: 0.3916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Loss and Accuracy Plots\n",
        "fig, ax = plt.subplots(2, 1)\n",
        "\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\n",
        "ax[0].plot(history.history['val_loss'], color='r', label=\"validation Loss\",axes=ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(history.history['accuracy'], color='b', label=\"Training Accuracy\")\n",
        "ax[1].plot(history.history['val_accuracy'], color='r', label=\"Validation Accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "KnuevER1QKYi",
        "outputId": "0323b6f2-d54e-475a-b7fa-abd9b0df51b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on validation data\n",
        "_, evaluation_score = model.evaluate(X_test, y_test)\n",
        "print(f'Evaluation Score: {int(evaluation_score * 100)} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx-7D9gdQSAf",
        "outputId": "b902b2bb-2578-4a61-ad80-c1a1bd51a885"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 4s 42ms/step - loss: 2.3454 - accuracy: 0.3850\n",
            "Evaluation Score: 38 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.join()"
      ],
      "metadata": {
        "id": "H32Kjr6hUtKV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "41cb165c138a4b09b2f346cafbc93c9e"
          ]
        },
        "outputId": "3fa97c14-45ff-403e-d435-8e700194da46"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 198... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41cb165c138a4b09b2f346cafbc93c9e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 30.02MB of 30.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>█▆▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.37534</td></tr><tr><td>best_epoch</td><td>50</td></tr><tr><td>best_val_loss</td><td>2.31423</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>loss</td><td>2.39888</td></tr><tr><td>val_accuracy</td><td>0.39157</td></tr><tr><td>val_loss</td><td>2.31999</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">fragrant-rain-1</strong>: <a href=\"https://wandb.ai/nrepesh/MLOPS-mini-cap-cifar/runs/3tzcuah2\" target=\"_blank\">https://wandb.ai/nrepesh/MLOPS-mini-cap-cifar/runs/3tzcuah2</a><br/>\n",
              "Find logs at: <code>./wandb/run-20211220_165906-3tzcuah2/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get classification report\n",
        "pred = np.argmax(model.predict(X_test), axis=1)\n",
        "test_y = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(test_y, pred, labels=list(range(len(labels)))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFh9h3zkQTKC",
        "outputId": "249d8ab8-335f-44b5-d813-dc5c88534d07"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.64      0.65        25\n",
            "           1       0.51      0.51      0.51        37\n",
            "           2       0.30      0.19      0.23        32\n",
            "           3       0.17      0.22      0.19        23\n",
            "           4       0.10      0.10      0.10        29\n",
            "           5       0.25      0.39      0.31        28\n",
            "           6       0.35      0.19      0.25        31\n",
            "           7       0.45      0.56      0.50        27\n",
            "           8       0.29      0.63      0.40        27\n",
            "           9       0.45      0.44      0.44        32\n",
            "          10       0.22      0.27      0.24        22\n",
            "          11       0.43      0.11      0.18        27\n",
            "          12       0.42      0.42      0.42        33\n",
            "          13       0.20      0.22      0.21        32\n",
            "          14       0.41      0.37      0.39        30\n",
            "          15       0.25      0.11      0.15        36\n",
            "          16       0.57      0.48      0.52        25\n",
            "          17       0.46      0.63      0.54        30\n",
            "          18       0.58      0.31      0.41        35\n",
            "          19       0.27      0.27      0.27        30\n",
            "          20       0.33      0.62      0.43        26\n",
            "          21       0.35      0.46      0.40        26\n",
            "          22       0.39      0.55      0.46        33\n",
            "          23       0.62      0.77      0.69        26\n",
            "          24       0.53      0.66      0.58        29\n",
            "          25       0.50      0.26      0.34        38\n",
            "          26       0.38      0.50      0.43        32\n",
            "          27       0.28      0.27      0.27        26\n",
            "          28       0.35      0.26      0.30        35\n",
            "          29       0.43      0.21      0.29        28\n",
            "          30       0.33      0.41      0.37        32\n",
            "          31       0.24      0.29      0.26        28\n",
            "          32       0.36      0.28      0.32        32\n",
            "          33       0.50      0.35      0.41        26\n",
            "          34       0.25      0.24      0.25        33\n",
            "          35       0.23      0.17      0.19        36\n",
            "          36       0.30      0.11      0.16        28\n",
            "          37       0.36      0.26      0.31        34\n",
            "          38       0.24      0.16      0.19        32\n",
            "          39       0.81      0.76      0.78        33\n",
            "          40       0.38      0.24      0.30        33\n",
            "          41       0.57      0.62      0.60        37\n",
            "          42       0.20      0.62      0.31        29\n",
            "          43       0.19      0.26      0.22        27\n",
            "          44       0.22      0.14      0.17        35\n",
            "          45       0.44      0.23      0.30        31\n",
            "          46       0.39      0.31      0.35        29\n",
            "          47       0.45      0.50      0.47        28\n",
            "          48       0.41      0.63      0.49        38\n",
            "          49       0.64      0.42      0.51        38\n",
            "          50       0.00      0.00      0.00        28\n",
            "          51       0.33      0.48      0.39        29\n",
            "          52       0.38      0.62      0.48        24\n",
            "          53       0.73      0.83      0.77        29\n",
            "          54       0.59      0.33      0.43        30\n",
            "          55       0.00      0.00      0.00        33\n",
            "          56       0.49      0.71      0.58        31\n",
            "          57       0.57      0.44      0.50        27\n",
            "          58       0.15      0.39      0.21        28\n",
            "          59       0.33      0.45      0.38        31\n",
            "          60       0.65      0.54      0.59        24\n",
            "          61       0.45      0.78      0.57        27\n",
            "          62       0.43      0.74      0.55        31\n",
            "          63       0.23      0.46      0.31        26\n",
            "          64       0.12      0.07      0.09        27\n",
            "          65       0.32      0.24      0.27        25\n",
            "          66       0.24      0.20      0.22        35\n",
            "          67       0.43      0.32      0.37        28\n",
            "          68       0.67      0.50      0.57        36\n",
            "          69       0.59      0.55      0.57        31\n",
            "          70       0.70      0.57      0.63        28\n",
            "          71       0.64      0.49      0.55        37\n",
            "          72       0.05      0.05      0.05        22\n",
            "          73       0.39      0.32      0.35        38\n",
            "          74       0.14      0.14      0.14        28\n",
            "          75       0.54      0.65      0.59        40\n",
            "          76       0.62      0.78      0.69        27\n",
            "          77       0.38      0.28      0.32        29\n",
            "          78       0.31      0.50      0.38        24\n",
            "          79       0.53      0.36      0.43        25\n",
            "          80       0.50      0.16      0.24        37\n",
            "          81       0.31      0.35      0.33        31\n",
            "          82       0.54      0.74      0.62        27\n",
            "          83       0.69      0.33      0.45        33\n",
            "          84       0.24      0.19      0.21        31\n",
            "          85       0.32      0.39      0.35        23\n",
            "          86       0.36      0.50      0.42        26\n",
            "          87       0.50      0.67      0.57        18\n",
            "          88       0.39      0.42      0.41        38\n",
            "          89       0.22      0.19      0.20        26\n",
            "          90       0.47      0.40      0.43        35\n",
            "          91       0.62      0.53      0.57        34\n",
            "          92       0.18      0.26      0.21        27\n",
            "          93       0.29      0.11      0.16        35\n",
            "          94       0.74      0.53      0.62        32\n",
            "          95       0.43      0.46      0.44        26\n",
            "          96       0.38      0.29      0.33        34\n",
            "          97       0.21      0.19      0.20        31\n",
            "          98       0.19      0.17      0.18        29\n",
            "          99       0.53      0.50      0.51        20\n",
            "\n",
            "    accuracy                           0.38      3000\n",
            "   macro avg       0.39      0.39      0.37      3000\n",
            "weighted avg       0.40      0.39      0.38      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the names of the class labels\n",
        "labels_names = []\n",
        "for i in range(len(labels)):\n",
        "    labels_names += [i]\n",
        "    \n",
        "reverse_mapping = dict(zip(labels_names, labels)) \n",
        "\n",
        "def mapper(value):\n",
        "    return reverse_mapping[value]"
      ],
      "metadata": {
        "id": "QkXTTjUoQ5ot"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-process image\n",
        "image_1 = load_img('/content/photo-1585110396000-c9ffd4e4b308.jpg', target_size=(32, 32))\n",
        "image_1 = img_to_array(image_1) \n",
        "image_1 = image_1 / 255.0\n",
        "prediction_image_1 = np.array(image_1)\n",
        "prediction_image_1 = np.expand_dims(image_1, axis=0)"
      ],
      "metadata": {
        "id": "LI2kpA0oQ7NQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get prediction\n",
        "prediction_1 = model.predict(prediction_image_1)\n",
        "value_1 = np.argmax(prediction_1)\n",
        "name_1 = mapper(value_1)\n",
        "print(f'Prediction is {name_1}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnBT28P5Q_vT",
        "outputId": "4c52c61d-d337-4de8-a645-ca38857f776a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction is mushroom.\n"
          ]
        }
      ]
    }
  ]
}